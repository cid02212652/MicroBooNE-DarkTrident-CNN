executable = inference_payload.sh
output = logs/infer_dmcnn.$(CLUSTER).out
error = logs/infer_dmcnn.$(CLUSTER).err
log = logs/infer_dmcnn.$(CLUSTER).log

request_gpus = 1
requirements = regexp("V100|A6000", string(TARGET.GPUs_DeviceName))

+MaxRuntime = 84000
queue
