{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b5a99c-7411-43a4-baf4-570038762a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM-CNN_model_20260116-10_22_PM_epoch_4_batch_id_1961_labels_2_title_0.001_AG_GN_LM_TRAINING_step_9821.pwf: 46 tensors\n",
      "resnet34_gn_model_20260123-12_20_AM_epoch_4_batch_id_1961_labels_2_step_9821.pwf: 110 tensors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "MPID_CKPT = Path(\"/home/hep/an1522/dark_tridents_wspace/outputs/weights/DM-CNN_model_20260116-10_22_PM_epoch_4_batch_id_1961_labels_2_title_0.001_AG_GN_LM_TRAINING_step_9821.pwf\")\n",
    "# MPID_CKPT2 = Path(\"/home/hep/an1522/dark_tridents_wspace/outputs/weights/DM-CNN_model_20251030-09_18_PM_epoch_4_batch_id_1961_labels_2_title_0.001_AG_GN_LM_TRAINING_step_9821.pwf\")\n",
    "RN34_CKPT = Path(\"/home/hep/an1522/dark_tridents_wspace/outputs/weights/resnet34_gn/resnet34_gn_model_20260123-12_20_AM_epoch_4_batch_id_1961_labels_2_step_9821.pwf\")\n",
    "\n",
    "def extract_state(ckpt_obj):\n",
    "    # matches your CLI helper logic (common key names) [file:3]\n",
    "    if isinstance(ckpt_obj, dict):\n",
    "        for k in [\"state_dict\", \"model_state_dict\", \"model\", \"net\", \"weights\"]:\n",
    "            if k in ckpt_obj and isinstance(ckpt_obj[k], dict):\n",
    "                return ckpt_obj[k]\n",
    "        return ckpt_obj\n",
    "    raise ValueError(\"Unsupported checkpoint format\")\n",
    "\n",
    "def load_state(path: Path):\n",
    "    ckpt = torch.load(str(path), map_location=\"cpu\")\n",
    "    state = extract_state(ckpt)\n",
    "    print(f\"{path.name}: {len(state)} tensors\")\n",
    "    return state\n",
    "\n",
    "mpid_state = load_state(MPID_CKPT)\n",
    "# mpid_state2 = load_state(MPID_CKPT2)\n",
    "rn34_state = load_state(RN34_CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282d7027-512c-425f-9d0e-03ad71a7076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPID:\n",
      "Top-level prefixes: [('features', 40), ('classifier', 6)]\n",
      "\n",
      "ResNet34_gn:\n",
      "Top-level prefixes: [('net', 110)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def summarize_prefixes(state, n=20):\n",
    "    keys = list(state.keys())\n",
    "    top = Counter(k.split(\".\")[0] for k in keys)\n",
    "    print(\"Top-level prefixes:\", top.most_common(n))\n",
    "\n",
    "print(\"MPID:\")\n",
    "summarize_prefixes(mpid_state)\n",
    "\n",
    "# print(\"MPID2:\")\n",
    "# summarize_prefixes(mpid_state2)\n",
    "\n",
    "print(\"\\nResNet34_gn:\")\n",
    "summarize_prefixes(rn34_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e6bce7-5777-4fac-9b43-15ed3f94c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example MPID module names: ['classifier.1', 'classifier.3', 'classifier.4', 'features.0', 'features.10', 'features.12', 'features.14', 'features.16', 'features.17', 'features.19', 'features.2', 'features.21', 'features.23', 'features.24', 'features.26', 'features.28', 'features.3', 'features.30', 'features.31', 'features.32', 'features.5', 'features.7', 'features.9']\n",
      "\n",
      "Example ResNet module names: ['net.layer1.0.bn1', 'net.layer1.0.bn2', 'net.layer1.0.conv1', 'net.layer1.0.conv2', 'net.layer1.1.bn1', 'net.layer1.1.bn2', 'net.layer1.1.conv1', 'net.layer1.1.conv2', 'net.layer1.2.bn1', 'net.layer1.2.bn2', 'net.layer1.2.conv1', 'net.layer1.2.conv2', 'net.layer2.0.bn1', 'net.layer2.0.bn2', 'net.layer2.0.conv1', 'net.layer2.0.conv2', 'net.layer2.0.downsample.0', 'net.layer2.0.downsample.1', 'net.layer2.1.bn1', 'net.layer2.1.bn2', 'net.layer2.1.conv1', 'net.layer2.1.conv2', 'net.layer2.2.bn1', 'net.layer2.2.bn2', 'net.layer2.2.conv1', 'net.layer2.2.conv2', 'net.layer2.3.bn1', 'net.layer2.3.bn2', 'net.layer2.3.conv1', 'net.layer2.3.conv2', 'net.layer3.0.bn1', 'net.layer3.0.bn2', 'net.layer3.0.conv1', 'net.layer3.0.conv2', 'net.layer3.0.downsample.0', 'net.layer3.0.downsample.1', 'net.layer3.1.bn1', 'net.layer3.1.bn2', 'net.layer3.1.conv1', 'net.layer3.1.conv2', 'net.layer3.2.bn1', 'net.layer3.2.bn2', 'net.layer3.2.conv1', 'net.layer3.2.conv2', 'net.layer3.3.bn1', 'net.layer3.3.bn2', 'net.layer3.3.conv1', 'net.layer3.3.conv2', 'net.layer3.4.bn1', 'net.layer3.4.bn2', 'net.layer3.4.conv1', 'net.layer3.4.conv2', 'net.layer3.5.bn1', 'net.layer3.5.bn2', 'net.layer3.5.conv1', 'net.layer3.5.conv2', 'net.layer4.0.bn1', 'net.layer4.0.bn2', 'net.layer4.0.conv1', 'net.layer4.0.conv2', 'net.layer4.0.downsample.0', 'net.layer4.0.downsample.1', 'net.layer4.1.bn1', 'net.layer4.1.bn2', 'net.layer4.1.conv1', 'net.layer4.1.conv2', 'net.layer4.2.bn1', 'net.layer4.2.bn2', 'net.layer4.2.conv1', 'net.layer4.2.conv2']\n"
     ]
    }
   ],
   "source": [
    "SUFFIXES = {\n",
    "    \"weight\", \"bias\",\n",
    "    \"running_mean\", \"running_var\", \"num_batches_tracked\"\n",
    "}\n",
    "\n",
    "def module_name_from_key(k: str):\n",
    "    parts = k.split(\".\")\n",
    "    if parts[-1] in SUFFIXES:\n",
    "        return \".\".join(parts[:-1])\n",
    "    return k\n",
    "\n",
    "def candidate_modules(state, must_contain=None):\n",
    "    mods = sorted({module_name_from_key(k) for k in state.keys()})\n",
    "    if must_contain:\n",
    "        mods = [m for m in mods if must_contain in m]\n",
    "    return mods\n",
    "\n",
    "mpid_modules = candidate_modules(mpid_state)\n",
    "# mpid_modules2 = candidate_modules(mpid_state2)\n",
    "rn34_modules = candidate_modules(rn34_state)\n",
    "\n",
    "# print(\"Example MPID module names:\", mpid_modules[:40])\n",
    "# print(\"\\nExample ResNet module names:\", [m for m in rn34_modules if m.startswith(\"net.layer\")][:40])\n",
    "\n",
    "print(\"Example MPID module names:\", mpid_modules)\n",
    "# print(\"Example MPID2 module names:\", mpid_modules2)\n",
    "print(\"\\nExample ResNet module names:\", [m for m in rn34_modules if m.startswith(\"net.layer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330ccb93-92ec-431c-ade8-904575c884a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPID CAM-ish candidates (first 80):\n",
      "  features.0\n",
      "  features.10\n",
      "  features.12\n",
      "  features.14\n",
      "  features.16\n",
      "  features.17\n",
      "  features.19\n",
      "  features.2\n",
      "  features.21\n",
      "  features.23\n",
      "  features.24\n",
      "  features.26\n",
      "  features.28\n",
      "  features.3\n",
      "  features.30\n",
      "  features.31\n",
      "  features.32\n",
      "  features.5\n",
      "  features.7\n",
      "  features.9\n",
      "\n",
      "ResNet34 CAM-ish candidates (layer* ones):\n",
      "  net.layer1.0.bn1\n",
      "  net.layer1.0.bn2\n",
      "  net.layer1.0.conv1\n",
      "  net.layer1.0.conv2\n",
      "  net.layer1.1.bn1\n",
      "  net.layer1.1.bn2\n",
      "  net.layer1.1.conv1\n",
      "  net.layer1.1.conv2\n",
      "  net.layer1.2.bn1\n",
      "  net.layer1.2.bn2\n",
      "  net.layer1.2.conv1\n",
      "  net.layer1.2.conv2\n",
      "  net.layer2.0.bn1\n",
      "  net.layer2.0.bn2\n",
      "  net.layer2.0.conv1\n",
      "  net.layer2.0.conv2\n",
      "  net.layer2.0.downsample.0\n",
      "  net.layer2.0.downsample.1\n",
      "  net.layer2.1.bn1\n",
      "  net.layer2.1.bn2\n",
      "  net.layer2.1.conv1\n",
      "  net.layer2.1.conv2\n",
      "  net.layer2.2.bn1\n",
      "  net.layer2.2.bn2\n",
      "  net.layer2.2.conv1\n",
      "  net.layer2.2.conv2\n",
      "  net.layer2.3.bn1\n",
      "  net.layer2.3.bn2\n",
      "  net.layer2.3.conv1\n",
      "  net.layer2.3.conv2\n",
      "  net.layer3.0.bn1\n",
      "  net.layer3.0.bn2\n",
      "  net.layer3.0.conv1\n",
      "  net.layer3.0.conv2\n",
      "  net.layer3.0.downsample.0\n",
      "  net.layer3.0.downsample.1\n",
      "  net.layer3.1.bn1\n",
      "  net.layer3.1.bn2\n",
      "  net.layer3.1.conv1\n",
      "  net.layer3.1.conv2\n",
      "  net.layer3.2.bn1\n",
      "  net.layer3.2.bn2\n",
      "  net.layer3.2.conv1\n",
      "  net.layer3.2.conv2\n",
      "  net.layer3.3.bn1\n",
      "  net.layer3.3.bn2\n",
      "  net.layer3.3.conv1\n",
      "  net.layer3.3.conv2\n",
      "  net.layer3.4.bn1\n",
      "  net.layer3.4.bn2\n",
      "  net.layer3.4.conv1\n",
      "  net.layer3.4.conv2\n",
      "  net.layer3.5.bn1\n",
      "  net.layer3.5.bn2\n",
      "  net.layer3.5.conv1\n",
      "  net.layer3.5.conv2\n",
      "  net.layer4.0.bn1\n",
      "  net.layer4.0.bn2\n",
      "  net.layer4.0.conv1\n",
      "  net.layer4.0.conv2\n",
      "  net.layer4.0.downsample.0\n",
      "  net.layer4.0.downsample.1\n",
      "  net.layer4.1.bn1\n",
      "  net.layer4.1.bn2\n",
      "  net.layer4.1.conv1\n",
      "  net.layer4.1.conv2\n",
      "  net.layer4.2.bn1\n",
      "  net.layer4.2.bn2\n",
      "  net.layer4.2.conv1\n",
      "  net.layer4.2.conv2\n"
     ]
    }
   ],
   "source": [
    "def filter_cam_layers(mods):\n",
    "    # Typical hook targets are convs or whole residual blocks (layerX / layerX.N) [file:3]\n",
    "    keep = []\n",
    "    for m in mods:\n",
    "        if any(s in m for s in [\"conv\", \"layer\", \"features\"]):\n",
    "            keep.append(m)\n",
    "    return keep\n",
    "\n",
    "mpid_cam = filter_cam_layers(mpid_modules)\n",
    "mpid_cam2 = filter_cam_layers(mpid_modules)\n",
    "rn34_cam = filter_cam_layers(rn34_modules)\n",
    "\n",
    "print(\"MPID CAM-ish candidates (first 80):\")\n",
    "for m in mpid_cam[:80]:\n",
    "    print(\" \", m)\n",
    "\n",
    "# print(\"MPID2 CAM-ish candidates (first 80):\")\n",
    "# for m in mpid_cam2[:80]:\n",
    "#     print(\" \", m)\n",
    "\n",
    "print(\"\\nResNet34 CAM-ish candidates (layer* ones):\")\n",
    "for m in rn34_cam:\n",
    "    if m.startswith(\"net.layer\"):\n",
    "        print(\" \", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710d057b-8b52-4001-b3e6-25e94738db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from contextlib import contextmanager\n",
    "\n",
    "def get_module_by_name(model: nn.Module, name: str) -> nn.Module:\n",
    "    name = str(name).strip()\n",
    "    for n, m in model.named_modules():\n",
    "        if n == name:\n",
    "            return m\n",
    "    raise KeyError(f\"Layer '{name}' not found in model.named_modules()\")\n",
    "\n",
    "@contextmanager\n",
    "def capture_activations_and_grads(layer: nn.Module):\n",
    "    cache = {\"acts\": None, \"grads\": None}\n",
    "\n",
    "    def fwd_hook(m, inp, out):\n",
    "        cache[\"acts\"] = out\n",
    "\n",
    "    def bwd_hook(m, grad_input, grad_output):\n",
    "        # grad_output is a tuple; grad wrt module output is grad_output[0]\n",
    "        cache[\"grads\"] = grad_output[0]\n",
    "\n",
    "    h1 = layer.register_forward_hook(fwd_hook)\n",
    "    h2 = layer.register_full_backward_hook(bwd_hook)\n",
    "    try:\n",
    "        yield cache\n",
    "    finally:\n",
    "        h1.remove()\n",
    "        h2.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19e94c2-f7f1-4095-ab9f-e54f2f2d9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_layer(model: nn.Module, x: torch.Tensor, layer_name: str, class_idx: int = 0):\n",
    "    model.eval()\n",
    "    layer = get_module_by_name(model, layer_name)\n",
    "\n",
    "    with capture_activations_and_grads(layer) as cache:\n",
    "        # Forward\n",
    "        logits = model(x)\n",
    "\n",
    "        # Backward for Grad-CAM-style methods\n",
    "        score = logits[:, class_idx].sum()\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        score.backward()\n",
    "\n",
    "    acts = cache[\"acts\"]\n",
    "    grads = cache[\"grads\"]\n",
    "\n",
    "    print(f\"\\n=== Layer: {layer_name} ({layer.__class__.__name__}) ===\")\n",
    "    print(\"logits:\", tuple(logits.shape), \" sample:\", logits.detach().cpu()[0].tolist())\n",
    "\n",
    "    if acts is None:\n",
    "        print(\"No activations captured (unexpected).\")\n",
    "        return\n",
    "\n",
    "    if not isinstance(acts, torch.Tensor):\n",
    "        print(\"Activation is not a tensor:\", type(acts))\n",
    "        return\n",
    "\n",
    "    print(\"acts shape:\", tuple(acts.shape), \"dtype:\", acts.dtype, \"device:\", acts.device)\n",
    "\n",
    "    # Expect [B,C,H,W] for CAM layers\n",
    "    if acts.ndim == 4:\n",
    "        B,C,H,W = acts.shape\n",
    "        a = acts.detach()\n",
    "        print(f\"spatial grid: {H} x {W}  (CAM pixels)\")\n",
    "        print(\"acts stats:\",\n",
    "              \"min\", float(a.min()), \"max\", float(a.max()),\n",
    "              \"mean\", float(a.mean()),\n",
    "              \"frac>0\", float((a>0).float().mean()))\n",
    "    else:\n",
    "        print(\"acts ndim is\", acts.ndim, \"(CAM methods typically want 4D [B,C,H,W])\")\n",
    "\n",
    "    if grads is None:\n",
    "        print(\"No gradients captured -> Grad-CAM/++ will fail for this layer.\")\n",
    "    else:\n",
    "        g = grads.detach()\n",
    "        print(\"grads shape:\", tuple(g.shape))\n",
    "        print(\"grads stats:\",\n",
    "              \"min\", float(g.min()), \"max\", float(g.max()),\n",
    "              \"mean\", float(g.mean()),\n",
    "              \"L2\", float(torch.sqrt(torch.mean(g*g))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27dcd147-b2ba-4b96-838b-bb555edbcf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPID(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): GroupNorm(64, 64, eps=1e-05, affine=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): GroupNorm(64, 64, eps=1e-05, affine=True)\n",
      "    (6): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
      "    (7): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): GroupNorm(96, 96, eps=1e-05, affine=True)\n",
      "    (10): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): GroupNorm(96, 96, eps=1e-05, affine=True)\n",
      "    (13): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
      "    (14): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): GroupNorm(128, 128, eps=1e-05, affine=True)\n",
      "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (18): ReLU()\n",
      "    (19): GroupNorm(128, 128, eps=1e-05, affine=True)\n",
      "    (20): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
      "    (21): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU()\n",
      "    (23): GroupNorm(160, 160, eps=1e-05, affine=True)\n",
      "    (24): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (25): ReLU()\n",
      "    (26): GroupNorm(160, 160, eps=1e-05, affine=True)\n",
      "    (27): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
      "    (28): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU()\n",
      "    (30): GroupNorm(192, 192, eps=1e-05, affine=True)\n",
      "    (31): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (32): GroupNorm(192, 192, eps=1e-05, affine=True)\n",
      "    (33): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=12288, out_features=1536, bias=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=1536, out_features=192, bias=True)\n",
      "    (4): Linear(in_features=192, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from mpid_net import mpid_net_binary\n",
    "\n",
    "def extract_state(ckpt_obj):\n",
    "    # same pattern your scripts use (state_dict/model_state_dict/model/net/weights) [file:1]\n",
    "    if isinstance(ckpt_obj, dict):\n",
    "        for k in [\"state_dict\", \"model_state_dict\", \"model\", \"net\", \"weights\"]:\n",
    "            if k in ckpt_obj and isinstance(ckpt_obj[k], dict):\n",
    "                return ckpt_obj[k]\n",
    "        return ckpt_obj\n",
    "    raise ValueError(\"Unsupported checkpoint format\")\n",
    "\n",
    "ckpt = torch.load(str(MPID_CKPT), map_location=\"cpu\")\n",
    "state = extract_state(ckpt)\n",
    "\n",
    "mpid_model = mpid_net_binary.MPID()\n",
    "mpid_model.load_state_dict(state, strict=True)\n",
    "mpid_model.eval()\n",
    "\n",
    "print(mpid_model)\n",
    "\n",
    "# ckpt2 = torch.load(str(MPID_CKPT2), map_location=\"cpu\")\n",
    "# state2 = extract_state(ckpt2)\n",
    "\n",
    "# mpid_model2 = mpid_net_binary.MPID()\n",
    "# mpid_model2.load_state_dict(state, strict=True)\n",
    "# mpid_model2.eval()\n",
    "\n",
    "# print(mpid_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b20f8e2-d841-4c24-94cb-ea02a3287059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBinaryWrapperLocal(\n",
      "  (net): ResNet(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "      (1): Linear(in_features=512, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_state(ckpt_obj):\n",
    "    if isinstance(ckpt_obj, dict):\n",
    "        for k in [\"state_dict\", \"model_state_dict\", \"model\", \"net\", \"weights\"]:\n",
    "            if k in ckpt_obj and isinstance(ckpt_obj[k], dict):\n",
    "                return ckpt_obj[k]\n",
    "        return ckpt_obj\n",
    "    raise ValueError(\"Unsupported checkpoint format\")\n",
    "\n",
    "def infer_norm_from_state(state):\n",
    "    # BatchNorm has running_mean/running_var buffers; GroupNorm doesn't. [file:1]\n",
    "    for k in state.keys():\n",
    "        if k.endswith(\"running_mean\") or k.endswith(\"running_var\"):\n",
    "            return \"bn\"\n",
    "    return \"gn\"\n",
    "\n",
    "def make_norm_layer(kind=\"gn\", gngroups=32):\n",
    "    kind = kind.lower()\n",
    "    if kind == \"bn\":\n",
    "        return lambda c: nn.BatchNorm2d(c)\n",
    "    if kind == \"gn\":\n",
    "        def gn(c):\n",
    "            g = min(int(gngroups), int(c))\n",
    "            while g > 1 and (c % g) != 0:\n",
    "                g -= 1\n",
    "            return nn.GroupNorm(g, c)\n",
    "        return gn\n",
    "    raise ValueError(\"kind must be 'bn' or 'gn'\")\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1   = norm_layer(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2   = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = self.relu(out + identity)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, norm_layer, inchannels=1, numclasses=2, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inchannels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1   = norm_layer(64)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block,  64, layers[0], norm_layer=norm_layer)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, norm_layer=norm_layer)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, norm_layer=norm_layer)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(nn.Dropout(p=float(dropout)), nn.Linear(512 * block.expansion, numclasses))\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, norm_layer=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "        layers = [block(self.inplanes, planes, stride, downsample, norm_layer)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, 1, None, norm_layer))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.layer4(self.layer3(self.layer2(self.layer1(x))))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ResNetBinaryWrapperLocal(nn.Module):\n",
    "    # Matches your checkpoint prefix style: net.layer4..., net.fc.1.weight, etc. [file:3]\n",
    "    def __init__(self, norm=\"gn\", gngroups=32, dropout=0.0, numclasses=2, inchannels=1):\n",
    "        super().__init__()\n",
    "        norm_layer = make_norm_layer(norm, gngroups=gngroups)\n",
    "        self.net = ResNet(BasicBlock, [3, 4, 6, 3], norm_layer=norm_layer,\n",
    "                          inchannels=inchannels, numclasses=numclasses, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def load_resnet34_from_ckpt(path, device=\"cpu\"):\n",
    "    ckpt = torch.load(str(path), map_location=\"cpu\")\n",
    "    state = extract_state(ckpt)\n",
    "    norm = infer_norm_from_state(state)\n",
    "    model = ResNetBinaryWrapperLocal(norm=norm, gngroups=32, dropout=0.0, numclasses=2, inchannels=1)\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    model.to(device).eval()\n",
    "    return model, norm\n",
    "\n",
    "RESNET_CKPT = Path(\"/home/hep/an1522/dark_tridents_wspace/outputs/weights/resnet34_gn/resnet34_gn_model_20260123-12_20_AM_epoch_4_batch_id_1961_labels_2_step_9821.pwf\")\n",
    "resnet_model, inferred_norm = load_resnet34_from_ckpt(RESNET_CKPT)\n",
    "\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add41a64-429b-4318-975d-6e4b88868ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mpid:\n",
      "\n",
      "=== Layer: features.7 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 96, 128, 128) dtype: torch.float32 device: cpu\n",
      "spatial grid: 128 x 128  (CAM pixels)\n",
      "acts stats: min -19.41550064086914 max 15.316720008850098 mean -0.032182786613702774 frac>0 0.5053749084472656\n",
      "grads shape: (1, 96, 128, 128)\n",
      "grads stats: min -0.0056997025385499 max 0.004124149214476347 mean -5.8910273992296425e-08 L2 0.00018462615844327956\n",
      "\n",
      "=== Layer: features.10 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 96, 126, 126) dtype: torch.float32 device: cpu\n",
      "spatial grid: 126 x 126  (CAM pixels)\n",
      "acts stats: min -71.86093139648438 max 50.46554946899414 mean -1.3355437517166138 frac>0 0.4587053656578064\n",
      "grads shape: (1, 96, 126, 126)\n",
      "grads stats: min -0.0012752788607031107 max 0.0007818647427484393 mean 3.5845580725890613e-08 L2 3.9940434362506494e-05\n",
      "\n",
      "=== Layer: features.12 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 96, 126, 126) dtype: torch.float32 device: cpu\n",
      "spatial grid: 126 x 126  (CAM pixels)\n",
      "acts stats: min -1.0890908241271973 max 8.448798179626465 mean 0.006790450308471918 frac>0 0.3304811418056488\n",
      "grads shape: (1, 96, 126, 126)\n",
      "grads stats: min -0.005302210338413715 max 0.0028486917726695538 mean 6.148665079308557e-07 L2 0.00020450390002224594\n",
      "\n",
      "=== Layer: features.14 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 128, 64, 64) dtype: torch.float32 device: cpu\n",
      "spatial grid: 64 x 64  (CAM pixels)\n",
      "acts stats: min -49.11840057373047 max 46.957340240478516 mean -0.24164509773254395 frac>0 0.48273277282714844\n",
      "grads shape: (1, 128, 64, 64)\n",
      "grads stats: min -0.002664414467290044 max 0.0017730327090248466 mean -2.418664024617101e-08 L2 7.741850276943296e-05\n",
      "\n",
      "=== Layer: features.16 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 128, 64, 64) dtype: torch.float32 device: cpu\n",
      "spatial grid: 64 x 64  (CAM pixels)\n",
      "acts stats: min -0.9967805743217468 max 7.541021347045898 mean 0.05476762726902962 frac>0 0.3481330871582031\n",
      "grads shape: (1, 128, 64, 64)\n",
      "grads stats: min -0.007138707209378481 max 0.0053448304533958435 mean 8.307196139867301e-07 L2 0.0003409996279515326\n",
      "\n",
      "=== Layer: features.17 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 128, 62, 62) dtype: torch.float32 device: cpu\n",
      "spatial grid: 62 x 62  (CAM pixels)\n",
      "acts stats: min -70.17558288574219 max 67.54521942138672 mean -1.2335745096206665 frac>0 0.4395771026611328\n",
      "grads shape: (1, 128, 62, 62)\n",
      "grads stats: min -0.0009990285616368055 max 0.0006817371468059719 mean -6.187990209127747e-08 L2 3.476328492979519e-05\n",
      "\n",
      "=== Layer: features.19 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 128, 62, 62) dtype: torch.float32 device: cpu\n",
      "spatial grid: 62 x 62  (CAM pixels)\n",
      "acts stats: min -0.89661705493927 max 10.716510772705078 mean 0.06669359654188156 frac>0 0.3252735733985901\n",
      "grads shape: (1, 128, 62, 62)\n",
      "grads stats: min -0.003217975376173854 max 0.0025501358322799206 mean -5.041717940912349e-07 L2 0.00025756697868928313\n",
      "\n",
      "=== Layer: features.2 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 64, 256, 256) dtype: torch.float32 device: cpu\n",
      "spatial grid: 256 x 256  (CAM pixels)\n",
      "acts stats: min -1.3283941745758057 max 11.956111907958984 mean 0.0014800707576796412 frac>0 0.3392033576965332\n",
      "grads shape: (1, 64, 256, 256)\n",
      "grads stats: min -0.014049941673874855 max 0.019424382597208023 mean 8.210607802539016e-07 L2 0.0006718195509165525\n",
      "\n",
      "=== Layer: features.21 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 160, 32, 32) dtype: torch.float32 device: cpu\n",
      "spatial grid: 32 x 32  (CAM pixels)\n",
      "acts stats: min -39.184356689453125 max 39.85468292236328 mean -1.2912253141403198 frac>0 0.42494505643844604\n",
      "grads shape: (1, 160, 32, 32)\n",
      "grads stats: min -0.0018577203154563904 max 0.0013994025066494942 mean 3.995033281967153e-08 L2 9.447734919376671e-05\n",
      "\n",
      "=== Layer: features.23 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 160, 32, 32) dtype: torch.float32 device: cpu\n",
      "spatial grid: 32 x 32  (CAM pixels)\n",
      "acts stats: min -0.9011655449867249 max 15.776643753051758 mean 0.18615880608558655 frac>0 0.3387512266635895\n",
      "grads shape: (1, 160, 32, 32)\n",
      "grads stats: min -0.007075272034853697 max 0.0062319147400557995 mean -3.843155809590826e-06 L2 0.0005502885323949158\n",
      "\n",
      "=== Layer: features.24 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 160, 30, 30) dtype: torch.float32 device: cpu\n",
      "spatial grid: 30 x 30  (CAM pixels)\n",
      "acts stats: min -111.81109619140625 max 80.74139404296875 mean -5.159329414367676 frac>0 0.3283194303512573\n",
      "grads shape: (1, 160, 30, 30)\n",
      "grads stats: min -0.00321444240398705 max 0.0037982165813446045 mean 5.125591950871922e-09 L2 7.319687574636191e-05\n",
      "\n",
      "=== Layer: features.26 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 160, 30, 30) dtype: torch.float32 device: cpu\n",
      "spatial grid: 30 x 30  (CAM pixels)\n",
      "acts stats: min -0.8523886799812317 max 13.725398063659668 mean 0.2112458497285843 frac>0 0.3999791741371155\n",
      "grads shape: (1, 160, 30, 30)\n",
      "grads stats: min -0.006184760946780443 max 0.007402516435831785 mean 8.595820872869808e-06 L2 0.0006849129567854106\n",
      "\n",
      "=== Layer: features.28 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 192, 16, 16) dtype: torch.float32 device: cpu\n",
      "spatial grid: 16 x 16  (CAM pixels)\n",
      "acts stats: min -62.34328079223633 max 32.50984191894531 mean -9.152003288269043 frac>0 0.1640421599149704\n",
      "grads shape: (1, 192, 16, 16)\n",
      "grads stats: min -0.1076309084892273 max 0.007972669787704945 mean -4.702645128418226e-06 L2 0.0007298373384401202\n",
      "\n",
      "=== Layer: features.29 (ReLU) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 192, 16, 16) dtype: torch.float32 device: cpu\n",
      "spatial grid: 16 x 16  (CAM pixels)\n",
      "acts stats: min 0.0 max 32.50984191894531 mean 0.6937063336372375 frac>0 0.1640421599149704\n",
      "grads shape: (1, 192, 16, 16)\n",
      "grads stats: min -2.7712860107421875 max 3.706371545791626 mean 9.701277108031814e-12 L2 0.1656360775232315\n",
      "\n",
      "=== Layer: features.3 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 64, 254, 254) dtype: torch.float32 device: cpu\n",
      "spatial grid: 254 x 254  (CAM pixels)\n",
      "acts stats: min -35.23135757446289 max 23.370588302612305 mean -0.06853113323450089 frac>0 0.5085901618003845\n",
      "grads shape: (1, 64, 254, 254)\n",
      "grads stats: min -0.003068425226956606 max 0.0031904091592878103 mean -4.8570431232519695e-08 L2 0.00011903118866030127\n",
      "\n",
      "=== Layer: features.30 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 192, 16, 16) dtype: torch.float32 device: cpu\n",
      "spatial grid: 16 x 16  (CAM pixels)\n",
      "acts stats: min -1.5238796472549438 max 18.066835403442383 mean 0.0026729798410087824 frac>0 0.1844075471162796\n",
      "grads shape: (1, 192, 16, 16)\n",
      "grads stats: min -0.01092727854847908 max 0.016051622107625008 mean -1.2126596385039767e-12 L2 0.0016808200161904097\n",
      "\n",
      "=== Layer: features.31 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 192, 14, 14) dtype: torch.float32 device: cpu\n",
      "spatial grid: 14 x 14  (CAM pixels)\n",
      "acts stats: min -60.511131286621094 max 54.8945426940918 mean 0.006758727133274078 frac>0 0.5007972121238708\n",
      "grads shape: (1, 192, 14, 14)\n",
      "grads stats: min -0.001094592153094709 max 0.0010334396502003074 mean 1.732370892787785e-13 L2 0.00019822119793388993\n",
      "\n",
      "=== Layer: features.32 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 192, 14, 14) dtype: torch.float32 device: cpu\n",
      "spatial grid: 14 x 14  (CAM pixels)\n",
      "acts stats: min -1.4101340770721436 max 1.2573087215423584 mean 0.0007989004370756447 frac>0 0.5011957883834839\n",
      "grads shape: (1, 192, 14, 14)\n",
      "grads stats: min -0.04148593172430992 max 0.03928713873028755 mean 5.7535868108971044e-05 L2 0.009905437007546425\n",
      "\n",
      "=== Layer: features.5 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 64, 254, 254) dtype: torch.float32 device: cpu\n",
      "spatial grid: 254 x 254  (CAM pixels)\n",
      "acts stats: min -0.9510167241096497 max 8.393492698669434 mean 0.0004509215650614351 frac>0 0.35283157229423523\n",
      "grads shape: (1, 64, 254, 254)\n",
      "grads stats: min -0.00609895633533597 max 0.006720962934195995 mean -7.717262207052045e-08 L2 0.0003595337620936334\n",
      "\n",
      "=== Layer: features.7 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 96, 128, 128) dtype: torch.float32 device: cpu\n",
      "spatial grid: 128 x 128  (CAM pixels)\n",
      "acts stats: min -19.41550064086914 max 15.316720008850098 mean -0.032182786613702774 frac>0 0.5053749084472656\n",
      "grads shape: (1, 96, 128, 128)\n",
      "grads stats: min -0.0056997025385499 max 0.004124149214476347 mean -5.8910273992296425e-08 L2 0.00018462615844327956\n",
      "\n",
      "=== Layer: features.9 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-1.540178656578064, 1.5494192838668823]\n",
      "acts shape: (1, 96, 128, 128) dtype: torch.float32 device: cpu\n",
      "spatial grid: 128 x 128  (CAM pixels)\n",
      "acts stats: min -0.9880565404891968 max 7.732419013977051 mean 0.04293091967701912 frac>0 0.3595345914363861\n",
      "grads shape: (1, 96, 128, 128)\n",
      "grads stats: min -0.0062719970010221004 max 0.005970494356006384 mean -5.582214726018719e-07 L2 0.00036906544119119644\n",
      "\n",
      "rn34_gn:\n",
      "\n",
      "=== Layer: net.layer1 (Sequential) ===\n",
      "logits: (1, 2)  sample: [-5.719934463500977, 5.7076544761657715]\n",
      "acts shape: (1, 64, 128, 128) dtype: torch.float32 device: cpu\n",
      "spatial grid: 128 x 128  (CAM pixels)\n",
      "acts stats: min 0.0 max 13.10782527923584 mean 1.5426139831542969 frac>0 0.8095808029174805\n",
      "grads shape: (1, 64, 128, 128)\n",
      "grads stats: min -0.003229965688660741 max 0.004319176077842712 mean -9.42396667369394e-08 L2 7.120427471818402e-05\n",
      "\n",
      "=== Layer: net.layer2 (Sequential) ===\n",
      "logits: (1, 2)  sample: [-5.719934463500977, 5.7076544761657715]\n",
      "acts shape: (1, 128, 64, 64) dtype: torch.float32 device: cpu\n",
      "spatial grid: 64 x 64  (CAM pixels)\n",
      "acts stats: min 0.0 max 17.7667293548584 mean 0.8484687209129333 frac>0 0.7529449462890625\n",
      "grads shape: (1, 128, 64, 64)\n",
      "grads stats: min -0.0030208430252969265 max 0.0048772250302135944 mean -3.393398628759314e-08 L2 7.437128806486726e-05\n",
      "\n",
      "=== Layer: net.layer3 (Sequential) ===\n",
      "logits: (1, 2)  sample: [-5.719934463500977, 5.7076544761657715]\n",
      "acts shape: (1, 256, 32, 32) dtype: torch.float32 device: cpu\n",
      "spatial grid: 32 x 32  (CAM pixels)\n",
      "acts stats: min 0.0 max 50.58474349975586 mean 0.8284612894058228 frac>0 0.6139602661132812\n",
      "grads shape: (1, 256, 32, 32)\n",
      "grads stats: min -0.00044746327330358326 max 0.0006978723686188459 mean 1.9567744402593235e-06 L2 4.4689739297609776e-05\n",
      "\n",
      "=== Layer: net.layer4 (Sequential) ===\n",
      "logits: (1, 2)  sample: [-5.719934463500977, 5.7076544761657715]\n",
      "acts shape: (1, 512, 16, 16) dtype: torch.float32 device: cpu\n",
      "spatial grid: 16 x 16  (CAM pixels)\n",
      "acts stats: min 0.0 max 10.599605560302734 mean 0.3970682919025421 frac>0 0.49541473388671875\n",
      "grads shape: (1, 512, 16, 16)\n",
      "grads stats: min -0.0006170511478558183 max 0.0006914469413459301 mean 1.2644690286833793e-05 L2 0.00020849861903116107\n",
      "\n",
      "=== Layer: net.layer4.2.conv2 (Conv2d) ===\n",
      "logits: (1, 2)  sample: [-5.719934463500977, 5.7076544761657715]\n",
      "acts shape: (1, 512, 16, 16) dtype: torch.float32 device: cpu\n",
      "spatial grid: 16 x 16  (CAM pixels)\n",
      "acts stats: min -1381.5936279296875 max 1007.0556030273438 mean -1.6038932800292969 frac>0 0.5143356323242188\n",
      "grads shape: (1, 512, 16, 16)\n",
      "grads stats: min -8.518393769918475e-06 max 7.765991540509276e-06 mean 9.076073226310655e-15 L2 1.1844648497572052e-06\n",
      "\n",
      "=== Layer: net.layer4.2.bn2 (GroupNorm) ===\n",
      "logits: (1, 2)  sample: [-5.719934463500977, 5.7076544761657715]\n",
      "acts shape: (1, 512, 16, 16) dtype: torch.float32 device: cpu\n",
      "spatial grid: 16 x 16  (CAM pixels)\n",
      "acts stats: min -15.17160415649414 max 6.6172590255737305 mean -0.1894425004720688 frac>0 0.27736663818359375\n",
      "grads shape: (1, 512, 16, 16)\n",
      "grads stats: min -0.0006170511478558183 max 0.0006203815573826432 mean -3.941744944313541e-05 L2 0.00011270245886407793\n"
     ]
    }
   ],
   "source": [
    "# x must be [1,1,512,512] on same device as model\n",
    "# class_idx: pick 0/1 depending which logit you treat as \"signal\"/\"background\"\n",
    "candidates_resnet = [\"net.layer1\", \"net.layer2\", \"net.layer3\", \n",
    "                     \"net.layer4\", \"net.layer4.2.conv2\", \"net.layer4.2.bn2\"]\n",
    "# candidates_mpid = [\"features.19\", \"features.20\", \"features.21\", \n",
    "#                     \"features.22\", \"features.23\", \"features.28\", \n",
    "#                     \"features.31\", \"features.32\"]\n",
    "\n",
    "candidates_mpid = ['features.7', 'features.10', 'features.12', \n",
    "                     'features.14', 'features.16', 'features.17', \n",
    "                     'features.19', 'features.2', 'features.21', \n",
    "                     'features.23', 'features.24', 'features.26', \n",
    "                     'features.28', 'features.29', 'features.3', \n",
    "                     'features.30', 'features.31', 'features.32', \n",
    "                     'features.5', 'features.7', 'features.9']\n",
    "\n",
    "# candidates_resnet = ['net.layer1.0.bn1', 'net.layer1.0.bn2', 'net.layer1.0.conv1', \n",
    "#                      'net.layer1.0.conv2', 'net.layer1.1.bn1', 'net.layer1.1.bn2', \n",
    "#                      'net.layer1.1.conv1', 'net.layer1.1.conv2', 'net.layer1.2.bn1', \n",
    "#                      'net.layer1.2.bn2', 'net.layer1.2.conv1', 'net.layer1.2.conv2', \n",
    "#                      'net.layer2.0.bn1', 'net.layer2.0.bn2', 'net.layer2.0.conv1', \n",
    "#                      'net.layer2.0.conv2', 'net.layer2.0.downsample.0', 'net.layer2.0.downsample.1', \n",
    "#                      'net.layer2.1.bn1', 'net.layer2.1.bn2', 'net.layer2.1.conv1', \n",
    "#                      'net.layer2.1.conv2', 'net.layer2.2.bn1', 'net.layer2.2.bn2', \n",
    "#                      'net.layer2.2.conv1', 'net.layer2.2.conv2', 'net.layer2.3.bn1',\n",
    "#                      'net.layer2.3.bn2', 'net.layer2.3.conv1', 'net.layer2.3.conv2', \n",
    "#                      'net.layer3.0.bn1', 'net.layer3.0.bn2', 'net.layer3.0.conv1', \n",
    "#                      'net.layer3.0.conv2', 'net.layer3.0.downsample.0', 'net.layer3.0.downsample.1',\n",
    "#                      'net.layer3.1.bn1', 'net.layer3.1.bn2', 'net.layer3.1.conv1', \n",
    "#                      'net.layer3.1.conv2', 'net.layer3.2.bn1', 'net.layer3.2.bn2', \n",
    "#                      'net.layer3.2.conv1', 'net.layer3.2.conv2', 'net.layer3.3.bn1', \n",
    "#                      'net.layer3.3.bn2', 'net.layer3.3.conv1', 'net.layer3.3.conv2', \n",
    "#                      'net.layer3.4.bn1', 'net.layer3.4.bn2', 'net.layer3.4.conv1', \n",
    "#                      'net.layer3.4.conv2', 'net.layer3.5.bn1', 'net.layer3.5.bn2', \n",
    "#                      'net.layer3.5.conv1', 'net.layer3.5.conv2', 'net.layer4.0.bn1', \n",
    "#                      'net.layer4.0.bn2', 'net.layer4.0.conv1', 'net.layer4.0.conv2', \n",
    "#                      'net.layer4.0.downsample.0', 'net.layer4.0.downsample.1', \n",
    "#                      'net.layer4.1.bn1', 'net.layer4.1.bn2', 'net.layer4.1.conv1', \n",
    "#                      'net.layer4.1.conv2', 'net.layer4.2.bn1', 'net.layer4.2.bn2', \n",
    "#                      'net.layer4.2.conv1', 'net.layer4.2.conv2']\n",
    "# candidates_mpid   = ['classifier.1', 'classifier.3', 'classifier.4',\n",
    "#                      'features.0', 'features.10', 'features.12', \n",
    "#                      'features.14', 'features.16', 'features.17', \n",
    "#                      'features.19', 'features.2', 'features.21', \n",
    "#                      'features.23', 'features.24', 'features.26', \n",
    "#                      'features.28', 'features.3', 'features.30', \n",
    "#                      'features.31', 'features.32', 'features.5', \n",
    "#                      'features.7', 'features.9']\n",
    "\n",
    "x = torch.randn(1, 1, 512, 512, requires_grad=False)\n",
    "\n",
    "print(\"\")\n",
    "print(\"mpid:\")\n",
    "\n",
    "for ln in candidates_mpid:\n",
    "    # print(\"\")\n",
    "    # print(\"mpid:\")\n",
    "    probe_layer(mpid_model, x, ln, class_idx=0)\n",
    "    # print(\"\")\n",
    "    # print(\"mpid2:\")\n",
    "    # probe_layer(mpid_model2, x, ln, class_idx=0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"rn34_gn:\")\n",
    "\n",
    "for ln in candidates_resnet:\n",
    "    probe_layer(resnet_model, x, ln, class_idx=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM-CNN (.venv)",
   "language": "python",
   "name": "dmc-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
